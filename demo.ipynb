{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b757158",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" src=\"https://github.com/gesiscss/orc/blob/f8fecffc6816085caa379653ea3cb0c902be4081/load_balancer/static/images/logo/logo_text.png?raw=true\">\n",
    "\n",
    "<h1> Workflow-Integrated Data Documentation </h1>\n",
    "<h2> A demonstration on the \"Call me sexist, but...\" data collection </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3629380a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> This notebook serves as a prototype to demonstrate the Workflow-Integrated Data Documentation idea. Using the collection of the \"Call me sexist, but...\" dataset as an example for a typical Computational Social Science research process, we are going to show how a researcher might use the existing functionality of Jupyter Notebooks to collect, explore and pre-process Twitter data. On top of this core functionality, we implemented a very basic sketch of what the Workflow-Integrated Data Documentation project's outcome might look like.<br><br>\n",
    "The \"Call me sexist, but...\" dataset was originally collected by colleagues at GESIS to study the nuances of sexism on online platforms like Twitter. The rationale behind the data collection were quite intuitive; by collecting Tweets that contained the keyphrase \"Call me sexist, but...\" from the Twitter API, the resulting dataset would most likely contain a number of sexist Tweets, as the keyphrase may be seen as a disclaimer for sexist content that follows.<br><br>\n",
    "The original dataset was collected for the publication <a href=https://ojs.aaai.org/index.php/ICWSM/article/view/18085>Call me sexist, but... Revisiting Sexism Using Psychological Scales and Adversarial Samples</a> and is publicly available from the GESIS Datorium (https://doi.org/10.7802/2251). This notebook attempts a basic, less complex replication of the original data collection. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e7b603",
   "metadata": {},
   "source": [
    "Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ea29eff",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (7.6.3)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from ipywidgets) (5.3.4)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from ipywidgets) (5.0.5)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from ipywidgets) (3.5.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: ipython>=4.0.0 in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from ipywidgets) (7.22.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from ipywidgets) (1.0.0)\n",
      "Requirement already satisfied: jupyter-client in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
      "Requirement already satisfied: tornado>=4.2 in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.4.4)\n",
      "Requirement already satisfied: decorator in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (5.0.6)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (52.0.0.post20210125)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (3.0.17)\n",
      "Requirement already satisfied: pygments in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (2.8.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.17.2)\n",
      "Requirement already satisfied: backcall in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (4.7.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (3.2.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (20.3.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.17.3)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.3.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.9.4)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.0.7)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.10.1)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.11.3)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.1.0)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.1)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from jupyter-core->nbformat>=4.2.0->ipywidgets) (227)\n",
      "Requirement already satisfied: pywinpty>=0.5 in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.7)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.14.5)\n",
      "Requirement already satisfied: pycparser in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.3)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.3)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: testpath in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.4.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: bleach in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.3.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.4.3)\n",
      "Requirement already satisfied: async-generator in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.9)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\froehlln\\anaconda3\\lib\\site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "606cca16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os, json, re, pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b45313",
   "metadata": {},
   "source": [
    "Loading the Twitter API credentials (important: do not share with anyone!) and handling authentification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af699444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling twitter authentication\n",
    "with open('twitter_tokens.json') as rd:\n",
    "    twitter_tokens = json.load(rd)\n",
    "bearer_token = twitter_tokens['bearer_token']\n",
    "\n",
    "def bearer_oauth(r):\n",
    "    r.headers['Authorization'] = f'Bearer {bearer_token}'\n",
    "    r.headers['User-Agent'] = 'v2FilteredStreamPython'\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28a1769",
   "metadata": {},
   "source": [
    "Setting parameters for connecting to the Twitter API v2 /tweets/search/all endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32d5ad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting connection parameters\n",
    "endpoint_url = 'https://api.twitter.com/2/tweets/search/all'\n",
    "\n",
    "params = {'query': '\"call me sexist, but\" -is:retweet',\n",
    "          'start_time': '2021-07-14T18:30:00Z',\n",
    "         'max_results': 500,\n",
    "         'tweet.fields': 'created_at,author_id,text'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f6da8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0612952e84604035ae68907e12bdb783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Add Data Documentation Cell', layout=Layout(height='80px', width='25%'), style=ButtonStyle‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>\n",
       "  code_show=true; \n",
       "  function code_toggle() {\n",
       "    if (code_show){\n",
       "        $('.cm-comment:contains(@hidden)').closest('div.input').hide();\n",
       "    } else {\n",
       "        $('.cm-comment:contains(@hidden)').closest('div.input').show();\n",
       "    }\n",
       "    code_show = !code_show\n",
       "  } \n",
       "  $( document ).ready(code_toggle);\n",
       "</script>\n",
       "<a href=\"javascript:code_toggle()\">Show hidden code</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2709d181e35453ab95208fb7be9b347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Select(options=('---', 'General Characteristics', 'Platform Affordances', 'Platform Coverage', 'Trace Selectio‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee69269a0584ae9a910fc84ae1d607c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Select(layout=Layout(height='220px', width='100%'), options=('---', 'Who collected the dataset and who funded ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a07e80cc154661a33f967b57186d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Select(layout=Layout(height='40px', width='100%'), options=('---', 'How were the relevant traces collected fro‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How were the relevant traces collected from the platform? Are there any technical constraints of the data collection method? If yes, how did those limit the dataset design?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac78b4907a141ac8ae979c5c3342726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Answer:', layout=Layout(height='80px', width='100%'), placeholder='Type someth‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==============================\n",
    "# @hidden\n",
    "import ipywidgets as widgets\n",
    "questions = {\n",
    "    'General Characteristics':{\n",
    "        'Who collected the dataset and who funded the process?': 'Who collected the dataset and who funded the process?',\n",
    "        'Where is the dataset hosted?': 'Where is the dataset hosted? Is the dataset distributed under a copyright or license?',\n",
    "        'What do the instances that comprise the dataset represent?': 'What do the instances that comprise the dataset represent? What data does each instance consist of?',\n",
    "        'How many instances are there in total in each category?': 'How many instances are there in total in each category (as defined by the instances‚Äô label), and - if applicable - in each recommended data split?',\n",
    "        'In which contexts and publications has the dataset been used already?': 'In which contexts and publications has the dataset been used already?',\n",
    "        'Are there alternative datasets that could be used for the measurement of the same or similar constructs?': 'Are there alternative datasets that could be used for the measurement of the same or similar constructs? Could they be a better fit? How do they differ?',\n",
    "        'Can the dataset collection be readily reproduced?': 'Can the dataset collection be readily reproduced given the current data access, the general context and other potentially interfering developments?',\n",
    "        'Were any ethical review processes conducted?': 'Were any ethical review processes conducted?',\n",
    "        'Did any ethical considerations limit the dataset creation?': 'Did any ethical considerations limit the dataset creation?',\n",
    "        'Are there any potential risks for individuals using the data?': 'Are there any potential risks for individuals using the data?'\n",
    "    },\n",
    "    'Platform Affordances':{\n",
    "        'How were the relevant traces collected from the platform?': 'How were the relevant traces collected from the platform? Are there any technical constraints of the data collection method? If yes, how did those limit the dataset design?'\n",
    "    },\n",
    "    'Platform Coverage':{\n",
    "        'What is known about the platform/s population?': 'What is known about the platform/s population?'\n",
    "    },\n",
    "    'Trace Selection':{\n",
    "        'How was the data associated with each instance acquired?': 'How was the data associated with each instance acquired? On what basis were the trace selection criteria chosen?',\n",
    "        'Over what timeframe was the data collected?': 'Over what timeframe was the data collected, and how might that timeframe have affected the collected data?'\n",
    "    },\n",
    "    'User Selection':{\n",
    "        'What is known about the dataset population?': 'What is known about the dataset population? Are there user groups systematically in- or excluded in/from the dataset in direct consequence of the trace selection criteria?'\n",
    "    },\n",
    "    'Trace Augmentation and Trace Measurement':{\n",
    "        'Is there a label or target associated with each instance?': 'Is there a label or target associated with each instance? If so, how were the labels or targets generated?'\n",
    "    },\n",
    "    'User Augmentation':{\n",
    "        'Have attributes and characteristics of individuals been inferred?': 'Have attributes and characteristics of individuals been inferred?'\n",
    "    },\n",
    "    'Trace Reduction':{\n",
    "        'Have traces been excluded?': 'Have traces been excluded? Why and by what criteria?'\n",
    "    },\n",
    "    'User Reduction':{\n",
    "        'Have users been excluded?': 'Have users been excluded? Why and by what criteria?'\n",
    "    },\n",
    "    'Adjustment':{\n",
    "        'Does the dataset provide information to adjust the results to a target population?': 'Does the dataset provide information to adjust the results to a target population? If so, is this information inferred or self-reported?'\n",
    "    }\n",
    "}\n",
    "\n",
    "all_questions = {\n",
    "    'Who collected the dataset and who funded the process?': 'Who collected the dataset and who funded the process?',\n",
    "    'Where is the dataset hosted?': 'Where is the dataset hosted? Is the dataset distributed under a copyright or license?',\n",
    "    'What do the instances that comprise the dataset represent?': 'What do the instances that comprise the dataset represent? What data does each instance consist of?',\n",
    "    'How many instances are there in total in each category?': 'How many instances are there in total in each category (as defined by the instances‚Äô label), and - if applicable - in each recommended data split?',\n",
    "    'In which contexts and publications has the dataset been used already?': 'In which contexts and publications has the dataset been used already?',\n",
    "    'Are there alternative datasets that could be used for the measurement of the same or similar constructs?': 'Are there alternative datasets that could be used for the measurement of the same or similar constructs? Could they be a better fit? How do they differ?',\n",
    "    'Can the dataset collection be readily reproduced?': 'Can the dataset collection be readily reproduced given the current data access, the general context and other potentially interfering developments?',\n",
    "    'Were any ethical review processes conducted?': 'Were any ethical review processes conducted?',\n",
    "    'Did any ethical considerations limit the dataset creation?': 'Did any ethical considerations limit the dataset creation?',\n",
    "    'Are there any potential risks for individuals using the data?': 'Are there any potential risks for individuals using the data?',\n",
    "    'How were the relevant traces collected from the platform?': 'How were the relevant traces collected from the platform? Are there any technical constraints of the data collection method? If yes, how did those limit the dataset design?',\n",
    "    'How was the data associated with each instance acquired?': 'How was the data associated with each instance acquired? On what basis were the trace selection criteria chosen?',\n",
    "    'Over what timeframe was the data collected?': 'Over what timeframe was the data collected, and how might that timeframe have affected the collected data?',\n",
    "    'What is known about the dataset population?': 'What is known about the dataset population? Are there user groups systematically in- or excluded in/from the dataset in direct consequence of the trace selection criteria?',\n",
    "    'What is known about the platform/s population?': 'What is known about the platform/s population?',\n",
    "    'Is there a label or target associated with each instance?': 'Is there a label or target associated with each instance? If so, how were the labels or targets generated?',\n",
    "    'Have attributes and characteristics of individuals been inferred?': 'Have attributes and characteristics of individuals been inferred?',\n",
    "    \n",
    "\n",
    "}\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "def track_question(change):\n",
    "    print(all_questions[change['new']])\n",
    "    text_answer = widgets.Textarea(value='',\n",
    "                                   placeholder='Type something',\n",
    "                                   description='Answer:',\n",
    "                                   disabled=False,\n",
    "                                   layout=widgets.Layout(width='100%', height='80px'))\n",
    "    display(text_answer)\n",
    "    \n",
    "def track_category(change):\n",
    "    select_question = widgets.Select(options=['---']+list(questions[change['new']].keys()),\n",
    "                                     value='---',\n",
    "                                     rows=5,\n",
    "                                     layout=widgets.Layout(width='100%', height=f'{20+20*len(list(questions[change[\"new\"]].keys()))}px'))\n",
    "    select_question.observe(track_question, names='value')\n",
    "    display(select_question)\n",
    "\n",
    "def select_category(b):\n",
    "    select_category = widgets.Select(options=['---']+list(questions.keys()), \n",
    "                                     value='---',\n",
    "                                     rows=len(list(questions.keys())))\n",
    "\n",
    "    select_category.observe(track_category, names='value')\n",
    "    display(select_category)\n",
    "    \n",
    "btn = widgets.Button(description='Add Data Documentation Cell',\n",
    "                    layout=widgets.Layout(width='25%', height='80px'))\n",
    "display(btn)\n",
    "btn.on_click(select_category)\n",
    "# ==============================\n",
    "\n",
    "HTML('''<script>\n",
    "  code_show=true; \n",
    "  function code_toggle() {\n",
    "    if (code_show){\n",
    "        $('.cm-comment:contains(@hidden)').closest('div.input').hide();\n",
    "    } else {\n",
    "        $('.cm-comment:contains(@hidden)').closest('div.input').show();\n",
    "    }\n",
    "    code_show = !code_show\n",
    "  } \n",
    "  $( document ).ready(code_toggle);\n",
    "</script>\n",
    "<a href=\"javascript:code_toggle()\">Show hidden code</a>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06435d1f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "*Platform Affordances Error*\n",
    "    \n",
    "**How were the relevant traces collected from the platform? Are there any technical constraints of the data collection method? If yes, how did those limit the dataset design?** \n",
    "\n",
    "The Tweets were collected from the Twitter API v2 /2/tweets/search/all endpoint. The query used to collect the Tweets was '\"call me sexist, but\" -is:retweet'. The data collection covers the period from 14.07.2021 to 14.07.2022, thus one full year.\n",
    "\n",
    "Collecting data from the /tweets/search/all endpoint means that - in theory - every Tweet that was posted during the specified time period and that matches the specified keyword or keyphrase can be collected. However, this form of retrospective collection of Tweets does not cover any Tweets that were removed by Twitter, removed by the author, or that have been made private through the author.\n",
    "\n",
    "For this data collection, this could mean that not all Tweets that were originally posted containing the phrase 'Call me sexist, but' during the period from 14.07.2021 to 14.07.2022 are included in the dataset. Since the phrase was chosen for being an indicator of potentially sexist content that might follow it, it is rather likely that some of the Tweets posted with that phrase have been removed afterwards. The reason for this could be that either Twitter considered the Tweet to be against its platform rules and has thus removed it, or that the author of the Tweet deleted it, for the backlash experienced/feared or because of changes in their attitude.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc1c132",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "*Trace Selection Error*\n",
    "    \n",
    "**How was the data associated with each instance acquired? On what basis were the trace selection criteria chosen?**\n",
    "    \n",
    "The Tweets for this dataset were collected through the Twitter search API, matching Tweets that contained the keyphrase ‚Äúcall me sexist, but‚Äù. With the idea of collecting sexists posts on Twitter, the rationale behind this choice of query was that any content following this phrase would most likely be sexist. They keyphrase was thus used as a disclaimer for sexist posts.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "754fdfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect tweets\n",
    "response = requests.request('GET', url=endpoint_url, auth=bearer_oauth, params=params)\n",
    "tweets = [[tweet['id'],tweet['author_id'],tweet['created_at'],tweet['text']] for tweet in response.json()['data']]\n",
    "pd_tweets = pd.DataFrame(tweets, columns=['tweet_id','author_id','tweet_created_at','tweet_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1db5d3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>tweet_created_at</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1546971137162285058</td>\n",
       "      <td>516572282</td>\n",
       "      <td>2022-07-12T21:33:55.000Z</td>\n",
       "      <td>@LoveHerMo @taritaribobari Call me sexist but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1546939984527204353</td>\n",
       "      <td>1505593407229595650</td>\n",
       "      <td>2022-07-12T19:30:07.000Z</td>\n",
       "      <td>@Jeanna350 She made that movie!! Call me sexis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1546852110712594434</td>\n",
       "      <td>1504479095433834504</td>\n",
       "      <td>2022-07-12T13:40:56.000Z</td>\n",
       "      <td>@Kidmonger Y'all will call me sexist but there...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1546578485954727936</td>\n",
       "      <td>730203963375689728</td>\n",
       "      <td>2022-07-11T19:33:39.000Z</td>\n",
       "      <td>Because that doesn‚Äôt even sound right. Call me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1546220247551713287</td>\n",
       "      <td>1544376727996170243</td>\n",
       "      <td>2022-07-10T19:50:09.000Z</td>\n",
       "      <td>@gailkimITSME Call me sexist but men and women...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>1417877712551698435</td>\n",
       "      <td>2416797894</td>\n",
       "      <td>2021-07-21T16:02:44.000Z</td>\n",
       "      <td>@ANTHONYBLOGAN Call me sexist....but I cant th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>1417739720927371268</td>\n",
       "      <td>1394699798641528836</td>\n",
       "      <td>2021-07-21T06:54:24.000Z</td>\n",
       "      <td>Call me sexist but Barri Eid to larkon ki hai ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>1417150090045583360</td>\n",
       "      <td>1024065971986870272</td>\n",
       "      <td>2021-07-19T15:51:25.000Z</td>\n",
       "      <td>call me sexist but i dont think i'm taking the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>1416741034269237248</td>\n",
       "      <td>1416738573248782341</td>\n",
       "      <td>2021-07-18T12:45:59.000Z</td>\n",
       "      <td>@GoddessLuciaaa you can call me misogynistic y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>1415743030284460038</td>\n",
       "      <td>1388441032841379841</td>\n",
       "      <td>2021-07-15T18:40:16.000Z</td>\n",
       "      <td>you can call me sexist but pick me kƒ±zlar bir ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>306 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id            author_id          tweet_created_at  \\\n",
       "0    1546971137162285058            516572282  2022-07-12T21:33:55.000Z   \n",
       "1    1546939984527204353  1505593407229595650  2022-07-12T19:30:07.000Z   \n",
       "2    1546852110712594434  1504479095433834504  2022-07-12T13:40:56.000Z   \n",
       "3    1546578485954727936   730203963375689728  2022-07-11T19:33:39.000Z   \n",
       "4    1546220247551713287  1544376727996170243  2022-07-10T19:50:09.000Z   \n",
       "..                   ...                  ...                       ...   \n",
       "301  1417877712551698435           2416797894  2021-07-21T16:02:44.000Z   \n",
       "302  1417739720927371268  1394699798641528836  2021-07-21T06:54:24.000Z   \n",
       "303  1417150090045583360  1024065971986870272  2021-07-19T15:51:25.000Z   \n",
       "304  1416741034269237248  1416738573248782341  2021-07-18T12:45:59.000Z   \n",
       "305  1415743030284460038  1388441032841379841  2021-07-15T18:40:16.000Z   \n",
       "\n",
       "                                            tweet_text  \n",
       "0    @LoveHerMo @taritaribobari Call me sexist but ...  \n",
       "1    @Jeanna350 She made that movie!! Call me sexis...  \n",
       "2    @Kidmonger Y'all will call me sexist but there...  \n",
       "3    Because that doesn‚Äôt even sound right. Call me...  \n",
       "4    @gailkimITSME Call me sexist but men and women...  \n",
       "..                                                 ...  \n",
       "301  @ANTHONYBLOGAN Call me sexist....but I cant th...  \n",
       "302  Call me sexist but Barri Eid to larkon ki hai ...  \n",
       "303  call me sexist but i dont think i'm taking the...  \n",
       "304  @GoddessLuciaaa you can call me misogynistic y...  \n",
       "305  you can call me sexist but pick me kƒ±zlar bir ...  \n",
       "\n",
       "[306 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 306 tweets collected in total\n",
    "pd_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e8180d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "*General Characteristics*\n",
    "    \n",
    "**What do the instances that comprise the dataset represent? What data does each instance consist of?**\n",
    "\n",
    "The instances in the dataset represent Tweets and have the data fields: 'tweet_id', 'author_id', 'tweet_created_at', 'tweet_text'.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "786818f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_created_at</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3303192821</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145554242</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009994417397043200</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215303514</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24622214</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359189395946041352</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355850989119676420</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354493816913461251</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351635026383937543</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977893740621778944</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>293 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     tweet_id  tweet_created_at  tweet_text\n",
       "author_id                                                  \n",
       "3303192821                 13                13          13\n",
       "145554242                   2                 2           2\n",
       "1009994417397043200         1                 1           1\n",
       "215303514                   1                 1           1\n",
       "24622214                    1                 1           1\n",
       "...                       ...               ...         ...\n",
       "1359189395946041352         1                 1           1\n",
       "1355850989119676420         1                 1           1\n",
       "1354493816913461251         1                 1           1\n",
       "1351635026383937543         1                 1           1\n",
       "977893740621778944          1                 1           1\n",
       "\n",
       "[293 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 293 different authors, with one author having written 13 tweets, one author having written 2 tweets, and the rest of the authors 1 tweet each \n",
    "pd_tweets.groupby('author_id').count().sort_values('tweet_id', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca88e903",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "*User Selection Error*\n",
    "    \n",
    "**What is known about the dataset population? Are there user groups systematically in- or excluded in/from the dataset in direct consequence of the trace selection criteria?**\n",
    "    \n",
    "The only user-related information collected in the dataset is the Twitter ID of a Tweet's author. This ID is used by Twitter to uniquely identify every one of its users but does not encode any further user characteristics. For this dataset, no additional demographics have been collected.\n",
    "    \n",
    "Based on the number of unique author IDs present in the dataset, it may be observed that the 306 Tweets collected in total have been posted by 293 different authors, with the most productive author being responsible for 13 Tweets, the second most productive author for 2 Tweets, and the remaining 286 authors having contributed only 1 Tweet each to the dataset.\n",
    "    \n",
    "As the only inclusion criterion for the dataset was the use of the keyphrase \"Call me sexist, but...\", any type of Twitter user - independent of characteristics or demographics - could have ended up in the dataset. Systematic exclusion from the dataset could then in theory still be an issue, if certain groups of users are less prone to use the keyphrase in their public postings on Twitter.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12bf232a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Tweet:  2021-07-15T18:40:16.000Z\n",
      "Last Tweet:   2022-07-12T21:33:55.000Z\n"
     ]
    }
   ],
   "source": [
    "# first and last tweet collected\n",
    "print('First Tweet: ',list(pd_tweets['tweet_created_at'])[-1])\n",
    "print('Last Tweet:  ',list(pd_tweets['tweet_created_at'])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3c7cd1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "*Trace Selection Error*\n",
    "    \n",
    "**Over what timeframe was the data collected, and how might that timeframe have affected the collected data?**\n",
    "    \n",
    "The first Tweet collected in the dataset was posted 15.07.2021, the last Tweet 12.07.2022. The collection period as specified in the search query was from 14.07.2021 to 14.07.2022, thus covering one whole year.    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "616643b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing tweets for crowdworker-annotation - removing the call-me-sexist prompt\n",
    "tweets_processed = [re.sub('[Cc]all me sexist[,.]* [Bb]ut','',tweet[3]) for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3ba2ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy-annotation of tweets\n",
    "import random\n",
    "\n",
    "def dummy_annotation(row):\n",
    "    return random.choice(['sexist','non-sexist'])\n",
    "\n",
    "pd_tweets['label'] = pd_tweets.apply(dummy_annotation, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2027a403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>tweet_created_at</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>non-sexist</th>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sexist</th>\n",
       "      <td>157</td>\n",
       "      <td>157</td>\n",
       "      <td>157</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tweet_id  author_id  tweet_created_at  tweet_text\n",
       "label                                                        \n",
       "non-sexist       149        149               149         149\n",
       "sexist           157        157               157         157"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class balance\n",
    "pd_tweets.groupby('label').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c4d4ce",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "*General Characteristics*\n",
    "    \n",
    "**How many instances are there in total in each category (as defined by the instances‚Äô label), and - if applicable - in each recommended data split?**\n",
    "    \n",
    "A total of 306 Tweets have been collected in the dataset, of which 149 are labelled as 'non-sexist' and 157 labelled as 'sexist'. There are no splits recommended for the dataset.    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10dfd2ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>tweet_created_at</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1465632388445310976</td>\n",
       "      <td>145554242</td>\n",
       "      <td>2021-11-30T10:42:46.000Z</td>\n",
       "      <td>üìñRead also the blog post about the \"'Call me s...</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>1450442868359897094</td>\n",
       "      <td>145554242</td>\n",
       "      <td>2021-10-19T12:45:02.000Z</td>\n",
       "      <td>#Blog post by Dr. Mattia Samory @hide_yourself...</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id  author_id          tweet_created_at  \\\n",
       "197  1465632388445310976  145554242  2021-11-30T10:42:46.000Z   \n",
       "225  1450442868359897094  145554242  2021-10-19T12:45:02.000Z   \n",
       "\n",
       "                                            tweet_text       label  \n",
       "197  üìñRead also the blog post about the \"'Call me s...  non-sexist  \n",
       "225  #Blog post by Dr. Mattia Samory @hide_yourself...  non-sexist  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# artifact: tweets discussing the publication of the original dataset are now also included\n",
    "pd_tweets[pd_tweets['author_id']=='145554242']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39d99409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet 1 from user with author_id 145554242:\n",
      " üìñRead also the blog post about the \"'Call me sexist but' Dataset\",https://t.co/d0hrPfUT4Q @hide_yourself https://t.co/Ien0zUvmMG \n",
      "_____________________________________________________\n",
      "Tweet 2 from user with author_id 145554242:\n",
      " #Blog post by Dr. Mattia Samory @hide_yourself: The ‚ÄúCall Me #Sexist But‚Äù #Dataset - An interesting piece about a dataset of over 10.000 #tweets - curated by a group of researchers - to study the multiple ways sexism appears in day-to-day communication. https://t.co/AgPzSrsiCS \n",
      "_____________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i,tweet in enumerate(pd_tweets[pd_tweets['author_id']=='145554242']['tweet_text']):\n",
    "    print(f'Tweet {i+1} from user with author_id 145554242:\\n',tweet,'\\n_____________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbd62eb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "*General Characteristics*\n",
    "    \n",
    "**Can the dataset collection be readily reproduced given the current data access, the general context and other potentially interfering developments?**\n",
    "    \n",
    "The original version of this dataset has been published in 2021, together with a study that introduces a novel approach to the challenge of defining sexism online in its many nuances. As the study is titled ‚ÄúCall me sexist, but.‚Äù : Revisiting Sexism Detection Using Psychological Scales and Adversarial Samples., any Tweet discussing the study or the dataset using their title would potentially end up in an attempt to recreate an updated version of the dataset.    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae4d207a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc6d693b29c44d89be005cc1f0916f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Export Data Documentation Cells', layout=Layout(height='80px', width='25%'), style=ButtonS‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>\n",
       "  code_show=true; \n",
       "  function code_toggle() {\n",
       "    if (code_show){\n",
       "        $('.cm-comment:contains(@hidden)').closest('div.input').hide();\n",
       "    } else {\n",
       "        $('.cm-comment:contains(@hidden)').closest('div.input').show();\n",
       "    }\n",
       "    code_show = !code_show\n",
       "  } \n",
       "  $( document ).ready(code_toggle);\n",
       "</script>\n",
       "<a href=\"javascript:code_toggle()\">Show hidden code</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==============================\n",
    "# @hidden\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import HTML\n",
    "    \n",
    "def export(b):\n",
    "    print('Successfully exported the Data Documentation Cells to TES-D.docx')\n",
    "\n",
    "btn = widgets.Button(description='Export Data Documentation Cells',\n",
    "                    layout=widgets.Layout(width='25%', height='80px'))\n",
    "display(btn)\n",
    "btn.on_click(export)\n",
    "# ==============================\n",
    "\n",
    "HTML('''<script>\n",
    "  code_show=true; \n",
    "  function code_toggle() {\n",
    "    if (code_show){\n",
    "        $('.cm-comment:contains(@hidden)').closest('div.input').hide();\n",
    "    } else {\n",
    "        $('.cm-comment:contains(@hidden)').closest('div.input').show();\n",
    "    }\n",
    "    code_show = !code_show\n",
    "  } \n",
    "  $( document ).ready(code_toggle);\n",
    "</script>\n",
    "<a href=\"javascript:code_toggle()\">Show hidden code</a>''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
